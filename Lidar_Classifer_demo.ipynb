{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEyoAwldykaO"
   },
   "source": [
    "# GIS U-Net\n",
    "\n",
    "A Workflow for applying a Convolutional Neural Network to Geospatial data.\n",
    "Input data is a multi layer GeoTiff.\n",
    "Output data is a geotiff, this demo is semantic segmentation, however regression is also possible.\n",
    "\n",
    "\n",
    "\n",
    "## How to use\n",
    ">Google Colab lets you run interactive python scripts (Jupyter Notebooks).\n",
    ">This demo has been set up to run by simply executing all cells one after another.\n",
    ">To run each cell press Shift-Enter\n",
    ">\n",
    ">If you do not want to train the network skip the *\"Training\"* section.\n",
    ">If you want to train the network from scratch, skip the cell that loads the pre-trained model.\n",
    ">\n",
    ">\n",
    ">## Data Prep\n",
    ">\n",
    "> ### Raster generation\n",
    ">\n",
    ">Lidar data is converted into multiple raster layers. We used LasTools. Specifically LasCanopy.\n",
    ">The Lidar point cloud (pcl) was flattened to move all ground points to 0m.\n",
    ">The resulting flattened pcl is split into slices at differing heights above ground. rasters where generated using relative point densisty for ground layer ( # of points in slice/ # of total points)  and normalized point density(# of points in slice/ # of points in and below slice) with a grid of 4m.\n",
    ">for the canopy and upper vegetation structure, percentile heights where used with a 1m grid.\n",
    ">\n",
    ">The resulting rasters should be merged into a single Geotiff (future updates may allow for independent files)\n",
    ">\n",
    ">\n",
    "> ### Training / Test Data\n",
    ">![Input Tile](https://github.com/tpet93/GIS_Neural_Network/raw/master/Images/InputTile.png) ![Training Tile](https://github.com/tpet93/GIS_Neural_Network/raw/master/Images/TrainingTile.png) \n",
    ">\n",
    ">Training / Test data is created by drawing polygons using GIS software.\n",
    ">Each polygon is labeled with a class (integer)\n",
    ">two attributes \"Training_Class\" and \"Test_Class\" are used to split polygons between training and test.\n",
    ">\n",
    ">\n",
    "> ### Google Drive\n",
    ">It is recommended to mount and store datasets in a google drive folder, this will allow automatic saving of snapshots and output data to a persistent storage location.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LE9_DvwLaTOe",
    "outputId": "f39883c8-349b-4a40-eae1-a0701f74486e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "#shows which GPU has been assigned.\n",
    "#T4 is significantly faster than K80 due to mixed precision support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sChCAmLOLOCe"
   },
   "source": [
    "## **Setup Environment**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QTv3rnO53tMQ"
   },
   "outputs": [],
   "source": [
    "'''Optional. If datasets are stored on google drive use this option (recomended)'''\n",
    "\n",
    "#gdrive is used to store snapshots of the network and is a good place to store large datasets for quick access\n",
    "\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive',force_remount=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kX_unhqhFbX"
   },
   "outputs": [],
   "source": [
    "#@title Install dependencys , this can take some time. { output-height: 40, display-mode: \"form\" }\n",
    "\n",
    "\n",
    "!pip install tifffile\n",
    "\n",
    "! rm -rf /root/.ssh/*\n",
    "! mkdir /root/.ssh\n",
    "!ssh-keyscan github.com >> /root/.ssh/known_hosts \n",
    "\n",
    "! git clone https://github.com/NVIDIA/apex\n",
    "% cd apex\n",
    "! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
    "% cd ..\n",
    "\n",
    "#!pip install tb-nightly  # Until 1.14 moves to the release channel\n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip -o ngrok-stable-linux-amd64.zip\n",
    "\n",
    "!wget https://raw.githubusercontent.com/postmates/gdal/master/scripts/gdal_merge.py -P /content/ -nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "F3-yFa4o0dCg",
    "outputId": "09d886b9-cb06-4651-bbac-6d8852c32e2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#@title Import Python Modules\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets\n",
    "from torchsummary import summary\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "    APEX_AVAILABLE = True\n",
    "except ModuleNotFoundError:\n",
    "    APEX_AVAILABLE = False\n",
    "print(APEX_AVAILABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wGUht6Iyozt"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/sh/4kzz3fcyhno3qxc/AACOKj2gDZTK019FpNrD24EYa?dl=1\n",
    "!unzip AACOKj2gDZTK019FpNrD24EYa?dl=1\n",
    "!unzip 9band_lidar_slices.zip  #Tifffile library seems to have issue with compressed tiffs when using memmap mode. zipping  the tiff as a work around\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "kl3SfrNgR7Ct"
   },
   "outputs": [],
   "source": [
    "#@title Get Modules from Github.\n",
    "\n",
    "!rm -rf GIS_Neural_Network\n",
    "\n",
    "!git clone https://github.com/tpet93/GIS_Neural_Network.git\n",
    "\n",
    "from GIS_Neural_Network.Modules import dataloaders as dl\n",
    "from GIS_Neural_Network.Modules import utils as ut\n",
    "from GIS_Neural_Network.Modules import loaders as ld\n",
    "from GIS_Neural_Network.Modules import models as models\n",
    "from GIS_Neural_Network.Modules import train as tr\n",
    "from GIS_Neural_Network.Modules import classify as cl\n",
    "\n",
    "import imp\n",
    "imp.reload(dl)\n",
    "imp.reload(ut)\n",
    "imp.reload(ld)\n",
    "imp.reload(tr)\n",
    "imp.reload(cl)\n",
    "imp.reload(models)# needs to be last?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7Hi0C3qF36SH",
    "outputId": "608b4aa0-a898-4cd4-89a7-75e326e28d57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://24c55db5.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "#@title Start TensorBoard\n",
    "LOG_DIR = '/content/runs/'\n",
    "\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR) \n",
    ")\n",
    "\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "get_ipython().system(' curl -s http://localhost:4040/api/tunnels | python3 -c     \"import sys, json; print(json.load(sys.stdin)[\\'tunnels\\'][0][\\'public_url\\'])\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amltwyVx7ymT"
   },
   "source": [
    "## **Generate Files**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "oSrY7ujLCexm",
    "outputId": "184f1cab-6225-4485-9ef9-9f599479ab7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 True 44.0\n",
      "1084 True 44.0\n"
     ]
    }
   ],
   "source": [
    "#@title Parameter input\n",
    "\n",
    "# Path Containing the Training Data\n",
    "\n",
    "color_file = '/content/9band_lidar-slices.tif'\n",
    "class_file = '/content/Ground_truth_polygons.gpkg'\n",
    "\n",
    "\n",
    "\n",
    "#number of U-Net Blocks\n",
    "depth = 4\n",
    "\n",
    "#Calculate padsize and input image dimensions \n",
    "neat = ut.find_neats(36,depth)\n",
    "isneat, ps = ut.calc_padsize(depth,neat)\n",
    "print(neat,isneat,ps)\n",
    "#this keeps the downscaling of our images to a even divisible number for each layer,it is not neccesesary but seems to be good practise.\n",
    "\n",
    "\n",
    "#Calculate image dimensions for final classifaction\n",
    "fullneat = ut.find_neats(128,depth)\n",
    "fisneat, ps = ut.calc_padsize(depth,neat)\n",
    "print(fullneat,fisneat,ps)\n",
    "\n",
    "\n",
    "#save image Dimensions\n",
    "tile_size = neat\n",
    "full_tile_size = fullneat\n",
    "\n",
    "#number of Classes to classifiy (+1 for ignore class 0)\n",
    "nc = 11\n",
    "\n",
    "\n",
    "# Define the bands to use in the input image and how to display them\n",
    "\n",
    "#9 band standard\n",
    "\n",
    "num_bands = 9\n",
    "\n",
    "#disable any special band selection\n",
    "bandtransform = None\n",
    "# def bandtransform(img):\n",
    "#     img = img[:,:,(1,2,3,4,5,6)]# only use understory layers\n",
    "#     return img\n",
    "\n",
    "\n",
    "num_bands = 9\n",
    "\n",
    "#show bands 1,2, and 0 as RGB channels\n",
    "bands = (1,2,0)\n",
    "#scale RGB channels to 0-1 (overflow is acceptable)\n",
    "dividers = [100,100,30]\n",
    "\n",
    "\n",
    "\n",
    "# #9 band exaggerated percentile\n",
    "# num_bands = 9\n",
    "\n",
    "# def bandtransform(img):\n",
    "#     img[:,:,(7,8,0)] = img[:,:,(7,8,0)]*100#this multiplies the canopy heights by 3 to bring them close to the 0-100 scale that percentiles have\n",
    "#     return img\n",
    "\n",
    "# bands = (1,-1,0)\n",
    "# dividers = [100,25,4000]\n",
    "\n",
    "\n",
    "\n",
    "#each region can be tiled multiple times with a random offset to increase the size of the the training data.\n",
    "#each tile already has a buffer around it to account for the cropping.\n",
    "#to disable set spt to 1 and  maxshiftsize to 0.\n",
    "\n",
    "\n",
    "# num of shifts per tile\n",
    "spt = 5\n",
    "#the amount a tile can be shifted by\n",
    "maxshiftsize = tile_size/2\n",
    "# maxshiftsize = 0\n",
    "\n",
    "\n",
    "#nullthresh  is the cut-off propertion to discard tiles that contain little or no classified pixels.\n",
    "\n",
    "#if countall = True then blackthresh will be a percentage of the pixels, \n",
    "#if False then the the value used is the average of: the number of rows and the number of columns that contain at least one non-zero pixel. \n",
    "#this is helpful for tiles containg long thin classes such as roads\n",
    "\n",
    "countall = False\n",
    "\n",
    "nullthresh = 0.01 #proportion of pixels to be labled in each training tile\n",
    "te_nullthresh = 0.01 #proportion of pixels to be labled in each test tile\n",
    "\n",
    "# an image to genereate a test output (best to user a smaller image than full dataset)\n",
    "# used to confirm settings are appropriate / working\n",
    "test_infolder = '/content/'\n",
    "test_infile = '9band_lidar-slices.tif'\n",
    "\n",
    "# the full image to genereate an output\n",
    "full_infolder = '/content/'\n",
    "full_infile = '9band_lidar-slices.tif'\n",
    "\n",
    "# a folder on the VM to store tiles/outputs in.\n",
    "workdir = '/content/Segmentation/'\n",
    "\n",
    "# where to store training tiles\n",
    "tr_color_folder = 'tr_Color/'\n",
    "tr_class_folder = 'tr_Class/'\n",
    "\n",
    "# where to store eval tiles\n",
    "te_color_folder = 'te_Color/'\n",
    "te_class_folder = 'te_Class/'\n",
    "\n",
    "# where to store the input full and testing tiles\n",
    "full_folder = 'Full/'\n",
    "test_folder = 'Test/'\n",
    "\n",
    "# where to store the generated full and testing tiles\n",
    "predicted_test_folder = 'Predicted_test/'\n",
    "predicted_full_folder = 'Predicted_full/'\n",
    "\n",
    "#where to store the model periodically\n",
    "checkpoint_path = '/content/GIS_Neural_Network/Models/'\n",
    "checkpoint_path = '/content/GIS_Neural_Network/'\n",
    "\n",
    "#where to store the hdf5 datasets\n",
    "\n",
    "tr_datasetpath = '/content/train/'\n",
    "te_datasetpath = '/content/eval/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dytHMMkb3fC-"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "------Caution------\n",
    "run this cell to remove all files, this will allow the next cell to generate new training tiles \n",
    "\n",
    "'''\n",
    "!rm -rf $workdir # Remove tiles to generate new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "47boPFkiLJp8"
   },
   "outputs": [],
   "source": [
    "#@title Generate Tiles from gpkg\n",
    "\n",
    "\n",
    "#each block can be commeented out depending on requirements\n",
    "\n",
    "if not os.path.exists(workdir):\n",
    "    os.mkdir(workdir)\n",
    "    print(\"Directory \" , workdir ,  \" Created \")\n",
    "\n",
    "    #generate Training Tiles\n",
    "    print('Generate training tiles')\n",
    "    dl.gen_trainingtilesfromgpkg(\n",
    "        colourfile = color_file,\n",
    "        classfile = class_file,\n",
    "        attribute = 'Training_Class',\n",
    "        workdir = workdir,\n",
    "        color_folder = tr_color_folder,\n",
    "        class_folder = tr_class_folder,\n",
    "        tilesize = tile_size,\n",
    "        maxshift = maxshiftsize,\n",
    "        shiftspertile = spt,\n",
    "        ps = ps,\n",
    "        nullthresh = nullthresh,\n",
    "        countall = countall)\n",
    "\n",
    "    #generate Evaluation Tiles\n",
    "    print('Generate evaluation tiles')\n",
    "    dl.gen_trainingtilesfromgpkg(\n",
    "        colourfile =  color_file,\n",
    "        classfile = class_file,\n",
    "        attribute = 'Test_Class',\n",
    "        workdir = workdir,\n",
    "        color_folder = te_color_folder,\n",
    "        class_folder = te_class_folder,\n",
    "        tilesize = tile_size,\n",
    "        maxshift = maxshiftsize,\n",
    "        shiftspertile = spt,\n",
    "        ps = ps,\n",
    "        nullthresh = te_nullthresh,\n",
    "        countall = countall)\n",
    "\n",
    "    #generate Test Tiles\n",
    "\n",
    "    print('Generate test dataset tiles')\n",
    "    dl.gen_fulltiles(\n",
    "        input_folder = test_infolder,\n",
    "        colorfile = test_infile,\n",
    "        workdir = workdir,\n",
    "        output_folder = test_folder,\n",
    "        tilesize = full_tile_size,\n",
    "        ps = ps)\n",
    "    \n",
    "#     generate Full Tiles, Comment the next block during training, testing to speed up.\n",
    "    print('Generate test full dataset tiles')\n",
    "    dl.gen_fulltiles(\n",
    "        input_folder = full_infolder,\n",
    "        colorfile = full_infile,\n",
    "        workdir = workdir,\n",
    "        output_folder = full_folder,\n",
    "        tilesize = full_tile_size,\n",
    "        ps = ps)\n",
    "\n",
    "    #Split the Full tiles down the middle to create artifical boundarys.\n",
    "    print('split training tiles')\n",
    "    dl.split_shuffle(\n",
    "        color_input_folder = workdir+tr_color_folder,\n",
    "        class_input_folder = workdir+tr_class_folder,\n",
    "        ps = ps,\n",
    "        nullthresh = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "Ljbw6DpuF2Z3",
    "outputId": "000fe8d8-061e-4f7b-823a-1ffcd17eeb77"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c9b3528cc74215a0b0c0d922751b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1389), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d2b5fd85b94a75b379f831af289367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=650), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Make Hdf5 datafiles\n",
    "\n",
    "dl.makehdf5(tr_datasetpath,workdir+tr_color_folder, workdir+tr_class_folder,int(ps),bandtransform = bandtransform,lbltransform = None)\n",
    "dl.makehdf5(te_datasetpath,workdir+te_color_folder, workdir+te_class_folder,int(ps),bandtransform = bandtransform,lbltransform = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RsVk9ZC1H4Jg"
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "pOMVkVq3or0M"
   },
   "outputs": [],
   "source": [
    "#@title Define Model\n",
    "#This cell also reset the model to a blank state\n",
    "if(APEX_AVAILABLE):\n",
    "    amp_handle = amp.init(enabled=True)\n",
    "\n",
    "model = models.UNetB(n_classes=nc, padding=False, up_mode='upsample',in_channels=num_bands,wf=5,batch_norm=True,activation = 'ELU',depth=depth,max_filters= 512).to(device)\n",
    "writer = SummaryWriter()\n",
    "torch.cuda.empty_cache()\n",
    "epoch = 0\n",
    "summary(model, input_size=(num_bands, tile_size, tile_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "JOBss-_Hlgn1"
   },
   "outputs": [],
   "source": [
    "#@title Load Per-Trained Model (skip this cell to train from scratch)\n",
    "\n",
    "ckpt = torch.load('/content/GIS_Neural_Network/Models/Unet-Lidar-9b-11C-ELU-d4wf5-140-Ev_Loss-0.834403.pth')\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# print(ckpt['state_dict'])\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "optimizer.load_state_dict(ckpt['opt_state_dict'])\n",
    "epoch = ckpt['epochs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "HTFfjbxZ4VRG"
   },
   "outputs": [],
   "source": [
    "#@title convert the model to amp (mixed precision)\n",
    "optimizer3 = optim.Adam(model.parameters(), lr=1e-3,weight_decay = 1e-2)\n",
    "optimizer4 = optim.Adam(model.parameters(), lr=1e-4,weight_decay = 1e-2)\n",
    "optimizer5 = optim.Adam(model.parameters(), lr=1e-5,weight_decay = 1e-2)\n",
    "optimizer6 = optim.Adam(model.parameters(), lr=1e-6,weight_decay = 1e-2)\n",
    "optimizer6 = optim.Adam(model.parameters(), lr=1e-6,weight_decay = 1e-6)\n",
    "optimizer7 = optim.Adam(model.parameters(), lr=1e-7)\n",
    "\n",
    "#convert the model to amp (mixed precision)\n",
    "model, [optimizer3, optimizer4, optimizer5, optimizer6, optimizer7] = amp.initialize(model,  [optimizer3, optimizer4, optimizer5, optimizer6, optimizer7],opt_level=\"O1\")#setup our optimizers and run the model through AMP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeegeYBxOFMa"
   },
   "source": [
    "##**Training**\n",
    "\n",
    "\n",
    "skip forward to Generate Outputs to generate map from pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "4KWsRWioT6g6"
   },
   "outputs": [],
   "source": [
    "#@title Define training factors matrix\n",
    "\n",
    "#this this matric allow us to configure the output class based on all the class probailitys.\n",
    "#this changes the prediciton strenghts for each class before picking the maximum.\n",
    "#i.e sav = np.matrix([0,0,1,0,0,0,.7,.7,.7,0]) would add the predicitons of classes 7,8,9\n",
    "# into the prediction value of class 3 before pick the class with the maximum prediciton value.\n",
    "\n",
    "\n",
    "pri = np.array([1,0,0,0,0,0,0,0,0,0])\n",
    "sec = np.array([0,1,0,0,0,0,0,0,0,0])\n",
    "sav = np.array([0,0,1,0,0,0,0,0,0,0])\n",
    "isl = np.array([0,0,0,1,0,0,0,0,0,0])\n",
    "ww =  np.array([0,0,0,0,1,0,0,0,0,0])    \n",
    "stu = np.array([0,0,0,0,0,1,0,0,0,0])\n",
    "hea = np.array([0,0,0,0,0,0,1,0,0,0])\n",
    "roa = np.array([0,0,0,0,0,0,0,1,0,0])\n",
    "ear = np.array([0,0,0,0,0,0,0,0,1,0])\n",
    "riv = np.array([0,0,0,0,0,0,0,0,0,1])\n",
    "\n",
    "factsmat = np.stack([pri,sec,sav,isl,ww,stu,hea,roa,ear,riv])\n",
    "\n",
    "#pad the matrix to account for the 0 class\n",
    "factsmat = np.pad(factsmat, (1,0), 'constant', constant_values=0)#add ignore class columns and rows\n",
    "factsmat[0][0]=1\n",
    "# print(factsmat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "ImvQ7QYVgNPR",
    "outputId": "7bf08697-6231-4e9a-bb14-813e62173366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Tiles:  1389\n",
      "Eval Tiles:  650\n"
     ]
    }
   ],
   "source": [
    "#@title Setup datasets\n",
    "\n",
    "batch_size = 20 #this is limited by GPU memory, (due to using mixed precision the memory usage will be far lower than that shown in the model summary )\n",
    "\n",
    "\n",
    "#print the number of tiles\n",
    "train_samples = len(os.listdir(workdir+tr_color_folder))\n",
    "eval_samples = len(os.listdir(workdir+te_class_folder))\n",
    "\n",
    "print ('Training Tiles: ',train_samples)\n",
    "print ('Eval Tiles: ',eval_samples)\n",
    "\n",
    "\n",
    "#optional transform for adding random noise to input image\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda x : torch.from_numpy(x.copy())),\n",
    "    transforms.Lambda(lambda x : torch.transpose(x,0,2)),#image gets flipped going from numpy to tensor\n",
    "    transforms.Lambda(lambda x : torch.transpose(x,1,2)),\n",
    "    transforms.Lambda(lambda x : x + torch.randn_like(x)*(0.06*100))# add noise with a mean of 0 and variance of 6\n",
    "    ])\n",
    "\n",
    "#set datatransforms to None  to ignore\n",
    "data_transforms =None\n",
    "\n",
    "\n",
    "traindataset = ld.HDF5Dataset(tr_datasetpath,data_transforms)\n",
    "evaldataset = ld.HDF5Dataset(te_datasetpath,None)\n",
    "\n",
    "\n",
    "loader_params = {'batch_size': 1, 'shuffle': False, 'num_workers': 1}\n",
    "class_data_loader = data.DataLoader(traindataset, **loader_params) # a loader to count all the pixels in each class, this loader has a batch size of 1\n",
    "\n",
    "loader_params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 1}\n",
    "train_data_loader = data.DataLoader(traindataset, **loader_params)\n",
    "\n",
    "loader_params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 1}\n",
    "eval_data_loader = data.DataLoader(evaldataset, **loader_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "zU8VdEhGJx9S",
    "outputId": "5949676a-9936-4dbd-f9d8-61c3fe679aec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f8dfda8baa4beda3c5bc218ff23d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1389), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          1.40833171  1.          1.74881432  2.87873158  0.\n",
      " 12.55532015 17.00379108 20.77867377 23.58905551 12.68446643]\n"
     ]
    }
   ],
   "source": [
    "#@title Get class weights\n",
    "\n",
    "#Counts the number of pixels and applies the inverse to account for unbalanced classes\n",
    "train_class_weights = ut.get_class_weights(class_data_loader,nc)\n",
    "\n",
    "#Adjust the weights depending on the importance of the class for our purposes\n",
    "train_class_weights =train_class_weights * [0,1,1,1,1.2,0.0,.8,.6,.6,.6,.6]\n",
    "\n",
    "# train_class_weights =train_class_weights * [0,1,1,1,1,1,1,1,1,1,1]\n",
    "\n",
    "print(train_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "87XI8EUpCVwf"
   },
   "outputs": [],
   "source": [
    "#@title Initialize training routine\n",
    "\n",
    "#initialize our training routine\n",
    "trainer = tr.train_model(\n",
    "    model = model,\n",
    "    device = device,\n",
    "    epoch = epoch,\n",
    "    train_loader = train_data_loader,\n",
    "    eval_loader = eval_data_loader,\n",
    "    image_path = workdir+tr_color_folder,\n",
    "    class_path = workdir+tr_class_folder,\n",
    "    evalimage_path = workdir+te_color_folder,\n",
    "    evalclass_path = workdir+te_class_folder,\n",
    "    writer = writer,# tensorboard Summary writer\n",
    "    checkpoint_path = checkpoint_path, # where to save the model\n",
    "    weightsmat = factsmat, \n",
    "    ps = ps , # number of pixels that are cropped on the output\n",
    "    bands = bands,  # bands to display in previews\n",
    "    dividers = dividers, # bring the bands to usefull value to display (0-1)\n",
    "    use_amp = True, #use automatic mixed precision\n",
    "    amp = amp,\n",
    "    label = 'Lidar-9b-11C-ELU-d4wf5', # the Label to Save the Model Files Under\n",
    "    print_every = 1, # print text output every (epoch)\n",
    "    show_every = 1, # show sample image  every (epoch)\n",
    "    eval_every = 1, # run eval dataset every (epoch)\n",
    "    save_every = 10, # save model every (epoch)\n",
    "    asses_every = 4) # every (n batches) asses precision and jaccard) slows down training but provides useful graphs\n",
    "    \n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(weight = torch.FloatTensor(train_class_weights).to(device), ignore_index=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "EGwqpij3Hh-3"
   },
   "outputs": [],
   "source": [
    "#@title show sample images\n",
    "ld.show_image(model,device,factsmat,eval_data_loader,ps,bands,dividers)\n",
    "\n",
    "ld.show_image(model,device,factsmat,train_data_loader,ps,bands,dividers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LppNM_G-p0ol",
    "outputId": "4349ba73-6adc-4a7e-a136-95b5180c6f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://f98dc402.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "#@title Restart Tensorboard\n",
    "#ngrok will die when the training is interupted, run this cell to resart it\n",
    "\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nL3GQNkSOFOk"
   },
   "source": [
    "Train network with decreasing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hx58O0mzp1X3"
   },
   "outputs": [],
   "source": [
    "trainer(criterion, optimizer3, num_epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6goS94u-PdR"
   },
   "outputs": [],
   "source": [
    "trainer(criterion, optimizer4, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C263OUH-9-29"
   },
   "outputs": [],
   "source": [
    "trainer(criterion, optimizer5, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2pYOjir-Pn-"
   },
   "outputs": [],
   "source": [
    "trainer(criterion, optimizer6, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_YYml248DWD"
   },
   "source": [
    "## **Generate Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "y633yiBg8Gdk"
   },
   "outputs": [],
   "source": [
    "#@title Define Final factors Matrix\n",
    "\n",
    "#here we can remove, replace, or reduce the prevalence of certain classes\n",
    "\n",
    "pri = np.array([1,0,0,0,0,0,0,0,0,0])\n",
    "sec = np.array([0,1,0,0,0,0,0,0,0,0])\n",
    "sav = np.array([0,0,1,0,0,0,0,0,0,0])\n",
    "isl = np.array([0,0,0,0.6,0,0,0,0,0,0])\n",
    "ww =  np.array([0,0,0,0,0,0,0,0,0,0])    \n",
    "stu = np.array([0,0,0,0,0,.6,0,0,0,0])\n",
    "hea = np.array([0,0,0,0,0,0,.8,0,0,0])\n",
    "roa = np.array([0,0,0,0,0,0,0,.7,0,0])\n",
    "ear = np.array([0,0,0,0,0,0,0,0,.7,0])\n",
    "riv = np.array([0,0,0,0,0,0,0,0,0,1])\n",
    "\n",
    "\n",
    "factsmat = np.stack([pri,sec,sav,isl,ww,stu,hea,roa,ear,riv])\n",
    "\n",
    "factsmat = np.pad(factsmat, (1,0), 'constant', constant_values=0)#add ignore class columns and rows\n",
    "factsmat[0][0]=1\n",
    "print(factsmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "OAeBPiHczcd1"
   },
   "outputs": [],
   "source": [
    "#@title Setup Dataloaders\n",
    "\n",
    "data_transforms = None\n",
    "\n",
    "# def bandtransform(img):#pick the same subset of bands as used for training\n",
    "#     img = img[:,:,(1,2,3,4,5,6)]# only use understory layers\n",
    "#     return img\n",
    "\n",
    "testdataset = ld.tifimagedataset(workdir+test_folder,bandtransform)\n",
    "\n",
    "fulldataset = ld.tifimagedataset(workdir+full_folder,bandtransform)\n",
    "\n",
    "loader_params = {'batch_size': 1, 'shuffle': False, 'num_workers': 1}\n",
    "test_data_loader = data.DataLoader(testdataset, **loader_params)\n",
    "full_data_loader = data.DataLoader(fulldataset, **loader_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "ww8qi_3Bzw00"
   },
   "outputs": [],
   "source": [
    "#@title Generate Test Map\n",
    "#test and full map are the same in this demo, \n",
    "#the test dataset is entended to be a smaller region\n",
    "#to allow quick testing of parameters before processing the full map.\n",
    "\n",
    "cl.generate_image2(model,device,test_data_loader,workdir,test_folder,predicted_test_folder,factsmat,ps,output = 'raw',average = True)\n",
    "\n",
    "filename = 'test_map.tif'\n",
    "command = cl.merge(workdir+predicted_test_folder,workdir,filename)\n",
    "! $command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "2GqjzZuRz2C9"
   },
   "outputs": [],
   "source": [
    "#@title Generate Full Map\n",
    "\n",
    "cl.generate_image2(model,device,full_data_loader,workdir,full_folder,predicted_full_folder,factsmat,ps,output = 'raw',average = True)\n",
    "#genrerate\n",
    "filename = 'full_map.tif'\n",
    "command = cl.merge(workdir+predicted_full_folder,workdir,filename)\n",
    "! $command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "6mhkPgvEz2wn"
   },
   "outputs": [],
   "source": [
    "#@title Copy Final Map to Google Drive\n",
    "\n",
    "#google drive must be mounted to avoid error.\n",
    "\n",
    "infile = workdir+filename\n",
    "!mv $infile \"/content/gdrive/My Drive/GIS/\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Lidar_Classifer_demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
